import json

gw = glob_wildcards("../../samples-enabled/{DATASET}/{NAME}/fold-{FOLD}/{TYPE}.fold-{FOLD_2}.bed", followlinks=True)
# print(gw)
# for D, N, F, T in zip(gw.DATASET, gw.NAME, gw.FOLD, gw.TYPE):
#     print(D, N, F, T)

def load_info(info_json):
    with open(info_json) as f:
        return json.loads(f.read())

DATASETS_INFO = dict()
for dataset in list(set(gw.DATASET)):
    DATASETS_INFO[dataset] = load_info(f'../../../datasets/{dataset}/info.json')


### ALL Rule ###
rule ALL:
    input:
        expand("processed/{DATASET}/{NAME}/fold-{FOLD}/{TYPE}.fold-{FOLD}.tokenized.tsv", zip, DATASET=gw.DATASET, NAME=gw.NAME, FOLD=gw.FOLD, TYPE=gw.TYPE)


################
### BERT-RBP ###
################

rule slop_bed:
    input:
        bed = "../../samples-enabled/{DATASET}/{NAME}/fold-{FOLD}/{TYPE}.fold-{FOLD}.bed"
    output:
        bed = temp("processed/{DATASET}/{NAME}/fold-{FOLD}/{TYPE}.fold-{FOLD}.bed")
    params:
        genomefile = lambda wc: f"../../../meta/genomes/{DATASETS_INFO[wc.DATASET]['genome']}/{DATASETS_INFO[wc.DATASET]['genome']}.genomefile",
        slop = 50,
    shell:
        "bedtools slop -g {params.genomefile} -b {params.slop} -i {input.bed} > {output.bed}"

rule bed_to_fasta:
    input:
        bed = "processed/{DATASET}/{NAME}/fold-{FOLD}/{TYPE}.fold-{FOLD}.bed"
    output:
        fasta = temp("processed/{DATASET}/{NAME}/fold-{FOLD}/{TYPE}.fold-{FOLD}.fasta")
    params:
        genome_fa = lambda wc: f"../../../meta/genomes/{DATASETS_INFO[wc.DATASET]['genome']}/{DATASETS_INFO[wc.DATASET]['genome']}.fa",
    shell:
        "bedtools getfasta -s -fi {params.genome_fa} -bed {input} > {output}"

rule fasta_to_upper:
    input:
        fasta = "processed/{DATASET}/{NAME}/fold-{FOLD}/{TYPE}.fold-{FOLD}.fasta"
    output:
        fasta = "processed/{DATASET}/{NAME}/fold-{FOLD}/{TYPE}.fold-{FOLD}.UPPER.fasta"
    run:
        with open(input.fasta) as f_in, open(output.fasta, 'w') as f_out:
            for line in f_in:
                assert line[0] == '>'
                print(line.strip(), file=f_out)
                print(f_in.readline().strip().upper(), file=f_out)

rule tokenize_fasta:
    input:
        fasta = "processed/{DATASET}/{NAME}/fold-{FOLD}/{TYPE}.fold-{FOLD}.UPPER.fasta"
    output:
        tsv = "processed/{DATASET}/{NAME}/fold-{FOLD}/{TYPE}.fold-{FOLD}.tokenized.tsv"
    params:
        label = lambda wc: '1' if wc.TYPE == 'positive' else '0'
    shell:
        'python scripts/tokenize-fasta.py {input.fasta} --label {params.label} --output {output.tsv}'
